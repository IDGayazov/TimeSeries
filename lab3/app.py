import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
import warnings
warnings.filterwarnings('ignore')

from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.arima.model import ARIMA
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from scipy import stats
from statsmodels.tsa.stattools import acf
import io

# =============================================================================
# –ú–û–î–ï–õ–ò –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø
# =============================================================================

def naive_forecast(train_series, horizon):
    """Naive forecast - –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"""
    return np.full(horizon, train_series[-1])

def snaive_forecast(train_series, horizon, seasonality=7):
    """Seasonal naive forecast - —Å–µ–∑–æ–Ω–Ω–æ–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ"""
    if len(train_series) < seasonality:
        return naive_forecast(train_series, horizon)
    
    predictions = []
    for i in range(horizon):
        predictions.append(train_series[-(seasonality - (i % seasonality))])
    return np.array(predictions)

def exponential_smoothing_forecast(train_series, horizon, seasonal_periods=7):
    """Exponential smoothing"""
    try:
        if len(train_series) > 2 * seasonal_periods:
            model = ExponentialSmoothing(
                train_series, 
                seasonal_periods=seasonal_periods,
                trend='add', 
                seasonal='add'
            )
            fitted_model = model.fit()
            return fitted_model.forecast(horizon)
        else:
            model = ExponentialSmoothing(train_series, trend='add')
            fitted_model = model.fit()
            return fitted_model.forecast(horizon)
    except:
        return snaive_forecast(train_series, horizon)

def arima_forecast(train_series, horizon, order=(1,1,1)):
    """ARIMA –º–æ–¥–µ–ª—å"""
    try:
        model = ARIMA(train_series, order=order)
        fitted_model = model.fit()
        return fitted_model.forecast(horizon)
    except:
        return exponential_smoothing_forecast(train_series, horizon)

def linear_regression_forecast(train_series, horizon, window=10):
    """–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    try:
        X, y = [], []
        for i in range(window, len(train_series)):
            X.append(train_series[i-window:i])
            y.append(train_series[i])
        
        model = LinearRegression()
        model.fit(X, y)
        
        predictions = []
        current_window = train_series[-window:].copy()
        
        for _ in range(horizon):
            pred = model.predict([current_window])[0]
            predictions.append(pred)
            current_window = np.append(current_window[1:], pred)
        
        return np.array(predictions)
    except:
        return naive_forecast(train_series, horizon)

def random_forest_forecast(train_series, horizon, window=10):
    """–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    try:
        X, y = [], []
        for i in range(window, len(train_series)):
            X.append(train_series[i-window:i])
            y.append(train_series[i])
        
        model = RandomForestRegressor(n_estimators=50, random_state=42, max_depth=5)
        model.fit(X, y)
        
        predictions = []
        current_window = train_series[-window:].copy()
        
        for _ in range(horizon):
            pred = model.predict([current_window])[0]
            predictions.append(pred)
            current_window = np.append(current_window[1:], pred)
        
        return np.array(predictions)
    except:
        return linear_regression_forecast(train_series, horizon)

# =============================================================================
# –£–¢–ò–õ–ò–¢–´ –ò –ú–ï–¢–†–ò–ö–ò
# =============================================================================

def calculate_metrics(y_true, y_pred):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
    mae = np.mean(np.abs(y_true - y_pred))
    mse = np.mean((y_true - y_pred) ** 2)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    
    return {
        'MAE': mae,
        'MSE': mse,
        'RMSE': rmse,
        'MAPE': mape
    }

def prepare_data(df, date_col, target_col, test_size=0.2):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    df_sorted = df.sort_values(date_col)
    series = df_sorted[target_col].values
    
    split_idx = int(len(series) * (1 - test_size))
    train_data = series[:split_idx]
    test_data = series[split_idx:]
    
    return train_data, test_data, series

def apply_boxcox(series, lambda_val=None):
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞"""
    if lambda_val is None:
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä lambda
        transformed, fitted_lambda = stats.boxcox(series + 1e-9)  # –¥–æ–±–∞–≤–ª—è–µ–º –º–∞–ª–µ–Ω—å–∫–æ–µ —á–∏—Å–ª–æ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    else:
        # –†—É—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ lambda
        if lambda_val == 0:
            transformed = np.log(series + 1e-9)
        else:
            transformed = (series ** lambda_val - 1) / lambda_val
        fitted_lambda = lambda_val
    
    return transformed, fitted_lambda

def inverse_boxcox(transformed, lambda_val):
    """–û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞"""
    if lambda_val == 0:
        return np.exp(transformed)
    else:
        return (transformed * lambda_val + 1) ** (1 / lambda_val)

# =============================================================================
# –û–°–ù–û–í–ù–û–ï –ü–†–ò–õ–û–ñ–ï–ù–ò–ï STREAMLIT
# =============================================================================

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="Time Series Forecast",
    page_icon="üìà",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.title("üìà –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ, –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –∏ –ø–æ–ª—É—á–∏—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑")

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    uploaded_file = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö", 
        type=['csv', 'parquet'],
        help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è CSV –∏ Parquet —Ñ–∞–π–ª—ã"
    )
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    if uploaded_file is not None:
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
        
        # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_parquet(uploaded_file)
        
        # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫
        date_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–æ–π", df.columns)
        target_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é", df.columns)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã
        df[date_col] = pd.to_datetime(df[date_col])
        df = df.sort_values(date_col)
        
        # –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        horizon = st.selectbox(
            "–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è",
            [1, 7, 30, 90],
            index=1,
            help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞"
        )
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        test_size = st.slider(
            "–î–æ–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (%)",
            min_value=10,
            max_value=50,
            value=20,
            help="–ü—Ä–æ—Ü–µ–Ω—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
        )

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π
        st.subheader("–í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π")
        
        models_to_use = {}
        
        # –ë–µ–Ω—á–º–∞—Ä–∫–∏
        st.markdown("**–ë–µ–Ω—á–º–∞—Ä–∫–∏:**")
        models_to_use['Naive'] = st.checkbox("Naive", value=True)
        models_to_use['Seasonal Naive'] = st.checkbox("Seasonal Naive", value=True)
        models_to_use['Exponential Smoothing'] = st.checkbox("Exponential Smoothing", value=True)
        
        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–æ–¥–µ–ª–∏
        st.markdown("**–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–æ–¥–µ–ª–∏:**")
        models_to_use['ARIMA'] = st.checkbox("ARIMA", value=True)
        models_to_use['Linear Regression'] = st.checkbox("Linear Regression", value=True)
        models_to_use['Random Forest'] = st.checkbox("Random Forest", value=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
        st.subheader("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è")
        transformation = st.radio(
            "–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞",
            ["–ê–≤—Ç–æ", "–†—É—á–Ω–æ–π Œª", "–ù–µ—Ç"],
            help="–°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏"
        )
        
        if transformation == "–†—É—á–Ω–æ–π Œª":
            lambda_val = st.slider(
                "Œª –∑–Ω–∞—á–µ–Ω–∏–µ",
                min_value=-2.0,
                max_value=2.0,
                value=0.5,
                step=0.1
            )
        else:
            lambda_val = None

        # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
        if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ", type="primary", use_container_width=True):
            with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ..."):
                results = {}
                metrics = {}
                
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                train_data, test_data, full_series = prepare_data(
                    df, date_col, target_col, test_size/100
                )
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if transformation != "–ù–µ—Ç":
                    train_transformed, fitted_lambda = apply_boxcox(train_data, lambda_val)
                else:
                    train_transformed = train_data
                    fitted_lambda = None
                
                # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–∞–∂–¥–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                for model_name, use_model in models_to_use.items():
                    if use_model:
                        try:
                            if model_name == 'Naive':
                                pred = naive_forecast(train_transformed, horizon)
                            elif model_name == 'Seasonal Naive':
                                pred = snaive_forecast(train_transformed, horizon, seasonality=7)
                            elif model_name == 'Exponential Smoothing':
                                pred = exponential_smoothing_forecast(train_transformed, horizon)
                            elif model_name == 'ARIMA':
                                pred = arima_forecast(train_transformed, horizon)
                            elif model_name == 'Linear Regression':
                                pred = linear_regression_forecast(train_transformed, horizon)
                            elif model_name == 'Random Forest':
                                pred = random_forest_forecast(train_transformed, horizon)
                            
                            # –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                            if transformation != "–ù–µ—Ç":
                                pred = inverse_boxcox(pred, fitted_lambda)
                            
                            results[model_name] = pred
                            metrics[model_name] = calculate_metrics(test_data[:horizon], pred)
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –≤ –º–æ–¥–µ–ª–∏ {model_name}: {str(e)}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ session state
                st.session_state.results = results
                st.session_state.metrics = metrics
                st.session_state.train_data = train_data
                st.session_state.test_data = test_data
                st.session_state.horizon = horizon
                st.session_state.df = df
                st.session_state.date_col = date_col
                st.session_state.target_col = target_col

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
if hasattr(st.session_state, 'results') and st.session_state.results:
    results = st.session_state.results
    metrics = st.session_state.metrics
    train_data = st.session_state.train_data
    test_data = st.session_state.test_data
    horizon = st.session_state.horizon
    df = st.session_state.df
    date_col = st.session_state.date_col
    target_col = st.session_state.target_col
    
    # –í–∫–ª–∞–¥–∫–∏
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", 
        "üìà –ú–µ—Ç—Ä–∏–∫–∏", 
        "üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞",
        "üíæ –≠–∫—Å–ø–æ—Ä—Ç"
    ])
    
    with tab1:
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        selected_model = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏",
            list(results.keys())
        )
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
        fig = go.Figure()
        
        # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        fig.add_trace(go.Scatter(
            x=list(range(len(train_data))),
            y=train_data,
            name="–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ",
            line=dict(color='blue')
        ))
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        fig.add_trace(go.Scatter(
            x=list(range(len(train_data), len(train_data) + len(test_data[:horizon]))),
            y=test_data[:horizon],
            name="–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è",
            line=dict(color='green')
        ))
        
        # –ü—Ä–æ–≥–Ω–æ–∑
        fig.add_trace(go.Scatter(
            x=list(range(len(train_data), len(train_data) + horizon)),
            y=results[selected_model],
            name=f"–ü—Ä–æ–≥–Ω–æ–∑ ({selected_model})",
            line=dict(color='red', dash='dash')
        ))
        
        fig.update_layout(
            title=f"–ü—Ä–æ–≥–Ω–æ–∑ –º–æ–¥–µ–ª–∏ {selected_model}",
            xaxis_title="–í—Ä–µ–º—è",
            yaxis_title="–ó–Ω–∞—á–µ–Ω–∏–µ",
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        # –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫
        metrics_df = pd.DataFrame(metrics).T
        metrics_df = metrics_df.round(4)
        
        # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ RMSE
        metrics_df['Rank'] = metrics_df['RMSE'].rank()
        
        st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–µ–π")
        st.dataframe(metrics_df.style.highlight_min(axis=0, color='lightgreen'))
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
        fig_metrics = go.Figure()
        
        for metric in ['RMSE', 'MAE', 'MAPE']:
            if metric in metrics_df.columns:
                fig_metrics.add_trace(go.Bar(
                    name=metric,
                    x=metrics_df.index,
                    y=metrics_df[metric],
                    text=metrics_df[metric].round(3)
                ))
        
        fig_metrics.update_layout(
            title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø–æ –º–æ–¥–µ–ª—è–º",
            barmode='group',
            height=400
        )
        
        st.plotly_chart(fig_metrics, use_container_width=True)
    
    with tab3:
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        diag_model = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏",
            list(results.keys()),
            key="diag_select"
        )
        
        if diag_model in results:
            residuals = test_data[:horizon] - results[diag_model]
            
            # –ì—Ä–∞—Ñ–∏–∫–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            fig_diag = make_subplots(
                rows=2, cols=2,
                subplot_titles=(
                    '–û—Å—Ç–∞—Ç–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏', 
                    '–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤',
                    'Q-Q Plot', 
                    'ACF –æ—Å—Ç–∞—Ç–∫–æ–≤'
                )
            )
            
            # –û—Å—Ç–∞—Ç–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
            fig_diag.add_trace(
                go.Scatter(y=residuals, mode='lines', name='–û—Å—Ç–∞—Ç–∫–∏'),
                row=1, col=1
            )
            fig_diag.add_hline(y=0, line_dash="dash", row=1, col=1)
            
            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
            fig_diag.add_trace(
                go.Histogram(x=residuals, name='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ'),
                row=1, col=2
            )
            
            # Q-Q plot
            qq = stats.probplot(residuals, dist="norm")
            fig_diag.add_trace(
                go.Scatter(x=qq[0][0], y=qq[0][1], mode='markers', name='Q-Q'),
                row=2, col=1
            )
            fig_diag.add_trace(
                go.Scatter(x=qq[0][0], y=qq[0][0]*qq[1][0] + qq[1][1], 
                          mode='lines', name='–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è'),
                row=2, col=1
            )
            
            # ACF
            acf_vals = acf(residuals, nlags=min(10, len(residuals)-1))
            fig_diag.add_trace(
                go.Bar(x=list(range(len(acf_vals))), y=acf_vals, name='ACF'),
                row=2, col=2
            )
            
            fig_diag.update_layout(height=600, showlegend=False)
            st.plotly_chart(fig_diag, use_container_width=True)
    
    with tab4:
        st.subheader("–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        models_to_export = st.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞",
            list(results.keys()),
            default=list(results.keys())[:2]
        )
        
        if models_to_export:
            # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
            export_data = {}
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—ã –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
            last_date = df[date_col].iloc[-1]
            future_dates = pd.date_range(
                start=last_date + pd.Timedelta(days=1), 
                periods=horizon, 
                freq='D'
            )
            
            export_data['date'] = future_dates
            
            for model in models_to_export:
                export_data[model] = results[model]
            
            export_df = pd.DataFrame(export_data)
            
            # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
            st.write("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞:")
            st.dataframe(export_df.head(10))
            
            # –§–æ—Ä–º–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∞
            export_format = st.radio("–§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞", ['CSV', 'Excel'])
            
            # –ö–Ω–æ–ø–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            col1, col2 = st.columns(2)
            
            with col1:
                if export_format == 'CSV':
                    csv = export_df.to_csv(index=False)
                    st.download_button(
                        "üì• –°–∫–∞—á–∞—Ç—å CSV",
                        data=csv,
                        file_name=f"forecast_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv",
                        mime="text/csv"
                    )
            
            with col2:
                if export_format == 'Excel':
                    excel_buffer = io.BytesIO()
                    export_df.to_excel(excel_buffer, index=False)
                    st.download_button(
                        "üì• –°–∫–∞—á–∞—Ç—å Excel",
                        data=excel_buffer.getvalue(),
                        file_name=f"forecast_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.xlsx",
                        mime="application/vnd.ms-excel"
                    )

else:
    # –°—Ç–∞—Ä—Ç–æ–≤—ã–π —ç–∫—Ä–∞–Ω
    st.markdown("""
    ## –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:
    
    1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ** - CSV –∏–ª–∏ Parquet —Ñ–∞–π–ª —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ä—è–¥–æ–º
    2. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã** - –≤—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç
    3. **–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏** - –æ—Ç–º–µ—Ç—å—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    4. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ** - –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
    
    ### –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏:
    - üìä **–ë–µ–Ω—á–º–∞—Ä–∫–∏**: Naive, Seasonal Naive, Exponential Smoothing
    - üß† **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ**: ARIMA, Linear Regression, Random Forest
    
    ### –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
    - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞
    - –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤ –º–æ–¥–µ–ª–µ–π
    - –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """)
